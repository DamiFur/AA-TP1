\documentclass[10pt,a4paper]{article}
\usepackage[paper=a4paper]{geometry}

\usepackage[utf8x]{inputenc}
\usepackage[spanish]{babel}

\usepackage{mathtools}
\usepackage{amsmath}
\usepackage{amsfonts}
\usepackage{amssymb}

\usepackage{xcolor}
\usepackage{listingsutf8}
\usepackage{booktabs}
\usepackage{hyperref}
\usepackage{multirow}

\usepackage{caption}
\usepackage{subcaption}

\usepackage{algorithm}
\usepackage[noend]{algpseudocode}

\usepackage{graphicx}
\usepackage{tikz}
\usepackage{relsize}
\usepackage{epstopdf}

\DeclarePairedDelimiter{\ceil}{\lceil}{\rceil}

% set the default code style
\lstset{
    frame=tb, % draw a frame at the top and bottom of the code block
    tabsize=4, % tab space width
    showstringspaces=false, % don't mark spaces in strings
    numbers=left, % display line numbers on the left
    commentstyle=\color{green}, % comment color
    keywordstyle=\color{blue}, % keyword color
    stringstyle=\color{red} % string color
}

% mathy stuff
\newtheorem{theorem}{Theorem}[section]
\newtheorem{lemma}[theorem]{Lemma}
\newtheorem{proposition}[theorem]{Proposición}
\newtheorem{corollary}[theorem]{Corollary}

\newenvironment{proof}[1][Demostración]{\begin{trivlist}
\item[\hskip \labelsep {\bfseries #1}]}{\end{trivlist}}
\newenvironment{definition}[1][Definición]{\begin{trivlist}
\item[\hskip \labelsep {\bfseries #1}]}{\end{trivlist}}
\newenvironment{example}[1][Example]{\begin{trivlist}
\item[\hskip \labelsep {\bfseries #1}]}{\end{trivlist}}
\newenvironment{remark}[1][Remark]{\begin{trivlist}
\item[\hskip \labelsep {\bfseries #1}]}{\end{trivlist}}

\newcommand{\qed}{\nobreak \ifvmode \relax \else
      \ifdim\lastskip<1.5em \hskip-\lastskip
      \hskip1.5em plus0em minus0.5em \fi \nobreak
      \vrule height0.75em width0.5em depth0.25em\fi}

\title{Aprendizaje Automatico \\ Trabajo Práctico 1 \\ Detección de Spam }

\newcommand{\order}[1]{$\mathcal{O}(#1)$}

\begin{document}

%% cover page

\maketitle

\bigskip

\begin{table}[h]
\centering
\begin{tabular}{|l l l l|}
\hline
Integrante       & \multicolumn{1}{c}{LU}     & Correo electrónico       	& Carrera \\ \hline
Martin Baigorria & \multicolumn{1}{c}{575/14} & martinbaigorria@gmail.com & computación (licenciatura) \\ 
Damián Furman & \multicolumn{1}{c}{936/11}& damian.a.furman@gmail.com & computación (licenciatura)\\
Germán Abrevaya & \multicolumn{1}{c}{-} & germanabrevaya@gmail.com & física (doctorado)\\ \hline
\end{tabular}
\end{table}

\vfill

\begin{center}
\textbf{Reservado para la cátedra}
\end{center}
\begin{table}[h]
\centering
\begin{tabular}{|l|l|l|}
\hline
Instancia       & Docente & Nota \\ \hline
Primera entrega &         &      \\ \hline
Segunda entrega &         &      \\ \hline
\end{tabular}
\end{table}

\newpage
\tableofcontents
\newpage

% end cover page

\section{Introducción}

El objetivo de este trabajo practico es experimentar con diferentes técnicas de aprendizaje automático para entrenar un clasificador de mensajes de correo electrónico en dos clases, 'spam' y 'ham'. Para ello, se utilizaran diferentes modelos y métodos para buscar los diferentes atributos que utilizaremos. Se experimentaran con diferentes técnicas de reducción de dimensionalidad. Además, se evaluaran los diferentes hiperparametros de cada modelo para poder buscar alguna forma de evitar hacer overfitting de los datos. Dejamos el 10\% de los datos como testing set, utilizando el resto para experimentar con los diferentes modelos.

\section{Extracción de atributos}

\subsection{Bag of words}

En una primera etapa, antes de intentar seleccionar atributos de forma manual, la idea fue analizar la frecuencia de cada palabra en cada mail, ignorando el orden de las palabras. Notar que los mails están en formato MIME, por lo que no se podía simplemente hacer un análisis de frecuencia sobre el MIME en plaintext, si no que había que utilizar un parser para luego poder analizar las diferentes partes de cada correo. Ademas, muchos de los correos no estaban en utf-8, lo que dificultaba el analisis. Por esa razón decidimos ignorarlos para el análisis de frecuencia.

Dado que el alto tiempo de computo para calcular la frecuencia de cada palabra en cada mail, decidimos simplemente tomar una variable binaria por mail que indica si la misma esta o no en el mismo. La idea fue calcular por clase cuantas veces aparecía cada palabra en el cuerpo de un correo, para luego ordenar todas las palabras por la diferencia absoluta en frecuencia relativa y de esa forma seleccionar los mejores atributos. Seguramente existe un orden mejor, pero lo que buscábamos era encontrar las palabras que mas distinguían entre las dos clases. Una idea que teníamos a priori además es que todas las conjunciones iban a aparecer con la misma frecuencia en ambas clases, por lo que al calcular el score se compensarían y no aparecerían en nuestros resultados finales. Además ignoramos todos los números, dado que creemos que no es un buen predictor.

En una primera instancia, decidimos tomar las mejores 200 palabras ordenadas por nuestro score para luego intentar seleccionar un subconjunto.

Por un lado creemos que todas las palabras que son sustantivos propios referidos a meses o nombres de personas no son buenos predictores. Lo mismo sucede con las conjunciones que finalmente terminaron apareciendo. De esta manera terminamos con el siguiente conjunto de palabras:

['please', 'original message', 'thanks', 'any', 'attached', 'questions', 'call', 'gas', 'date', 'corp', 'file',
	'energy', 'need', 'meeting', 'group', 'power', 'following', 'there', 'final', 'should', 'more', 'schedule',
	'review', 'think', 'week', 'some', 'deal', 'start', 'scheduling', 'contract', 'money', 'professional', 'been',
	'last', 'work', 'schedules', 'issues', 'viagra', 'however', 'contact', 'thank', 'between', 'solicitation', 'comments',
	'sex', 'messages', 'discuss', 'software', 'save', 'received', 'site', 'changes', 'txt', 'advertisement', 'parsing', 'prices',
	'morning', 'click', 'sure', 'visit', 'stop', 'only', 'working', 'next', 'trading', 'plan', 'tomorrow',
	'awarded', 'soft', 'detected', 'now', 'like', 'about', 'doc', 'who', 'windows', 'basis', 'online', 'product', 'conference',
	'prescription', 'products', 'best', 'fyi', 'point', 'agreement', 'regarding', 'forward', 'north', 'family', 'world', 'team',
	'process', 'help', 'cialis', 'adobe', 'down', 'results', 'thousand', 'first', 'issue', 'link', 'offers', 'note',
	'scheduled', 'management', 'capacity', 'market', 'bill', 'employees', 'daily', 'dollars']

\pagebreak

Por un lado unificamos las palabras 'original' y 'message', que en general muestran mensajes donde se hizo 'reply' o 'reply all'. Por otro lado, la palabra 'enron' aparecía bastante, lo que nos hizo pensar que el dataset que teníamos era el de Enron. Nos cuestionamos un poco que tan representativo es este dataset, dado que corresponde en general a mails corporativos. Notar que este mismo procedimiento se puede hacer para el titulo de los correos.

\subsection{Selección manual}

Luego de seleccionar los primeros atributos utilizando nuestra variacion de Bag of Words, decidimos elegir algunos otros atributos de forma manual. Estos fueron:

\begin{itemize}
	\item has\_closing\_tags
	\item has\_links
	\item cant\_capital
	\item capital\_in\_a\_row
	\item is\_multipart
\end{itemize}

Con estos atributos buscamos captar distintas propiedades frecuentes en los mails de spam: la presencia de links hacia páginas web de contenido malicioso o de spam, el formato HTML que otorga formato a cierta publicidad, la presencia de muchas palabras en mayúscula o títulos o subtítulos con varias letras con mayúsculas seguidas

A su vez, a las palabras determinadas por el Bag of Words le agregamos varias palabras que consideramos de posible aparición frecuente en mails de spam, a saber: offer, sex, viagra, Nigeria, discount entre varias otras

\section{Modelos}

Luego de definir nuestros atributos, probamos distintos modelos con el objetivo de evaluar su performance. Decidimos utilizar para nuestra comparación Naive Bayes, Decision Tree Classifier, Random Forest Classifier, Support Vector Machine, K Nearest Neighbours y AdaBoost. Éste último es similar a la técnica de boosting vista en clase, en la cual la salida de otros algoritmos de machine learning (``weak learners'') son combinadas en una suma pesada que representa la salida final del clasificador. La principal diferencia de un simple boosting respecto a AdaBoostes que este último es adaptativo en el sentido de que los weak learners subsiguientes son a su vez orientados para corregir las instancias mal clasificadas por los anteriores weak learners.

Antes de entrenar los modelos, se separó el 10\% de los datos totales para ser empleados como testing set y dar una medida más realista del desempeño de los modelos, entrenados con el 90\% restante de los datos.

% AdaBoost is sensitive to noisy data and outliers. AdaBoost training process selects only those features known to improve the predictive power of the model, reducing dimensionality and potentially improving execution time as irrelevant features do not need to be computed.

\section{Resultados}

A contiunación se presentarán para distintos modelos el tiempo de cómputo para entrenar al modelo (sin cross-validation), \emph{Train mean accuracy} (calculado sobre los datos de entrenamiento empleando un K-Folding Cross Validation con K = 10), cantidad de falsos y verdaderos casos positivos y negativos (calculados en base a la predicción de sobre el training set), \textit{precision} y \textit{recall}, definidos como:

\begin{align*}
\text{precision}& =\frac{\text{verdaderos positivos}}{\text{verdaderos positivos} + \text{falsos positivos}}&
\text{recall}& =\frac{\text{verdaderos positivos}}{\text{verdaderos positivos} + \text{falsos negativos}}&
\end{align*}



%Los resultados son los siguientes:
%
%\begin{table}[H]
%	\centering
%	\label{my-label}
%	\begin{tabular}{|l|l|l|l|l|l|}
%		\hline
%		\textbf{}             & \multicolumn{1}{c|}{\textbf{Rand. Forest}} & \multicolumn{1}{c|}{\textbf{Decision Tree}} & \multicolumn{1}{c|}{\textbf{SVM}} & \multicolumn{1}{c|}{\textbf{Naive Bayes}} & \multicolumn{1}{c|}{\textbf{kNN}} \\ \hline
%		Train mean accuracy    & 0.9538                                      & 0.9204                                      & 0.7933                            & 0.8059                                    & 0.8714                            \\ \hline
%		false positives       & 169                                         & 354                                         & 400                               & 1321                                      & 762                               \\ \hline
%		false negatives       & 247                                         & 362                                         & 1460                              & 426                                       & 395                               \\ \hline
%		true positives        & 4187                                        & 4086                                        & 3017                              & 4100                                      & 4131                              \\ \hline
%		true negatives        & 4397                                        & 4198                                        & 4123                              & 3153                                      & 3712                              \\ \hline
%		precision             & 0.9612                                      & 0.9203                                      & 0.8829                            & 0.7563                                    & 0.8443                            \\ \hline
%		recall                & 0.9443                                      & 0.9186                                      & 0.6739                            & 0.9059                                    & 0.9127                            \\ \hline
%		tiempo de cómputo (s) & 272.41                                      & 34.48                                       & 8220                 & 0.32                                      & 1181.95                           \\ \hline
%	\end{tabular}
%\end{table}





\subsection{Support Vector Machine}

Este método resultó impráctico debido al descomunal tiempo de computo necesario para entrenar el modelo. Quitándole 90 atributos calculados mediante Bag of Words el tiempo de cómputo para entrenar al modelo (sin cross-validation) fue de 2:17 horas. El Test mean accuracy resultó en este caso de 0.7933, la precision fue de 0.8829 y el recall, 0.6739. SVM utiliza quadratic programming lo cual conlleva un gran tiempo de cálculo cuando se trabaja con muchas dimensiones. No hay un criterio marcado de localidad para buscar hiperplanos separadores. Para sacarle más provecho a este método haría falta un kernel especifico.

\subsection{Naive Bayes}

Naive Bayes tiene la interesante propiedad de dar resultados acpetables pagando un tiempo de cómputo mínimo (tarda 0.32 segundos en entrenarse sobre el corpus de texto completo compuesto por 9 mil mails). Sin embargo, sus resultados no son aceptables en términos de un clasificador real. Principalmente porque, como se puede ver en el Cuadro \ref{naive}, si bien logra un \textit{accuracy} de un 80\%, genera una gran cantidad de falsos positivos en relación a los falsos negativos (\textit{recall} es de un 90\% mientras que \textit{precision} es de un 75\%). Naive Bayes considera cada uno de los atributos como un factor independiente de los otros atributos que aporta 'probabilisticamente' a la decisión sobre la clasificación de un elemento. Por esto decidimos quitar varios de sus atributos e ir agregándoselos por partes para de esta manera comprobar cómo varían los resultados obtenidos.

\begin{table}[H]
	\centering
	\begin{tabular}{|l|l|l|l|}
		\hline
		\textbf{}          & \multicolumn{1}{c|}{\textbf{10 Atributos}} & \multicolumn{1}{c|}{\textbf{65 Atributos}} & \multicolumn{1}{c|}{\textbf{130 Atributos}} \\ \hline
		Train mean accuracy & 0.49                                       & 0.6162                                     & 0.8059                                      \\ \hline
		false positives    & 4465                                       & 3269                                       & 1321                                        \\ \hline
		false negatives    & 125                                        & 185                                        & 426                                         \\ \hline
		true positives     & 4266                                       & 4285                                       & 4100                                        \\ \hline
		true negatives     & 144                                        & 1261                                       & 3153                                        \\ \hline
		precision          & 0.4886                                     & 5672                                       & 0.7563                                      \\ \hline
		recall             & 0.9715                                     & 0.9586                                     & 0.9059                                      \\ \hline
	\end{tabular}
	\caption{Resultados de Naive Bayes.}
		\label{naive}
\end{table}

Lo primero que podemos observar es que el clasificador Naive Bayes es muy sensible a la cantidad de atributos: parecería mejorar invariablemente en la medida que se agregan más. Esto sucede debido a que como cada atributo se considera independiente del resto y aporta una 'porción' de la probabilidad, al agregar más atributos la probabilidad total debería estar más afinada. Por otro lado, Naive Bayes no distingue distintas importancias entre los atributos, por lo que la efectividad de éste método también está supeditada a que la elección de los atributos que se agregan sea correcta.

Otra observación que puede realizarse es que cuando el clasificador no tiene suficiente cantidad de atributos tiende a clasificar todo en la misma categoría. En el caso de nuestra experiencia puede verse como con 10 atributos casi todos los mails fueron clasificados como Spam, lo cual genera que la métrica de \textit{precisión} sea bajísima mientras que el \textit{recall} tiene valores muy altos.


\subsection{Random Forests}

El tiempo de cómputo de un modelo Random Forest con todos los atributos y con 100 árboles fue de 272.41 segundos. Se realizaron varias pruebas con el este clasificador variando uno de sus hiperparámetros más importantes: la cantidad de árboles a utilizar. En el Cuadro \ref{rf} se puede ve cómo este hiperparámetro afecta los resultados en términos de predicción.

\begin{table}[H]
	\centering
	\begin{tabular}{|l|l|l|l|l|l|}
		\hline
		\multicolumn{1}{|c|}{\textbf{}} & \multicolumn{1}{c|}{\textbf{30 árboles}} & \multicolumn{1}{c|}{\textbf{50 árboles}} & \multicolumn{1}{c|}{\textbf{100 árboles}} & \textbf{150 árboles} & \textbf{200 árboles} \\ \hline
		Test mean accuracy              & 0.9518                                   & 0.9521                                   & 0.9538                                    & 0.9566               & 0.9529               \\ \hline
		false positives                 & 150                                      & 155                                      & 169                                       & 144                  & 158                  \\ \hline
		false negatives                 & 284                                      & 276                                      & 247                                       & 247                  & 266                  \\ \hline
		true positives                  & 4256                                     & 4296                                     & 4187                                      & 4256                 & 4247                 \\ \hline
		true negatives                  & 4310                                     & 4123                                     & 4397                                      & 4353                 & 4329                 \\ \hline
		precision                       & 0.9660                                   & 0.9652                                   & 0.9612                                    & 0.9673               & 0.9641               \\ \hline
		recall                          & 0.9374                                   & 0.9396                                   & 0.9443                                    & 0.9451               & 0.9411               \\ \hline
	\end{tabular}
		\caption{Resultados de Random Forest.}
		\label{rf}
\end{table}

En primer lugar se puede observar que aumentar la cantidad de árboles en general tiende a mejorar la \textit{accuracy} aunque su variación es relativamente pequeña (alrededor del 0,2\%). Sin embargo, con un exceso de arboles la \textit{accuracy} comienza a disminuir, aunque también con una tasa de decrecimiento baja. En general la eficiencia de este algoritmo como clasificador para nuestro cuerpo de datos no parece ser muy sensible ante variaciones de la cantidad de árboles empleada, al menos en el rango de 30 a 200 árboles. Aún así, el mejor resultado, tanto en términos de accuracy como de recall y de precision, se obtuvo al correr Random Forest con 150 árboles.

\subsection{kNN:}

Para K Nearest Neigbours consideramos intentar mejorar los resultados a partir de variar los k vecinos considerados. Mientras que en una primera instancia utilizamos un k = 5, testeamos luego los resultados de aplicar un k = 10 y k = 20

\begin{table}[H]
	\centering
	\label{my-label}
	\begin{tabular}{|l|l|l|l|}
		\hline
		\multicolumn{1}{|c|}{\textbf{}} & \multicolumn{1}{c|}{\textbf{K = 5}} & \multicolumn{1}{c|}{\textbf{K = 10}} & \multicolumn{1}{c|}{\textbf{K = 20}} \\ \hline
		Train mean accuracy              & 0.8714                              & 0.8127                               & 0.7949                               \\ \hline
		false positives                 & 762                                 & 686                                  & 758                                  \\ \hline
		false negatives                 & 395                                 & 1000                                 & 1088                                 \\ \hline
		true positives                  & 4131                                & 3468                                 & 3444                                 \\ \hline
		true negatives                  & 3712                                & 3846                                 & 3710                                 \\ \hline
		precision                       & 0.8443                              & 0.8348                               & 0.8196                               \\ \hline
		recall                          & 0.9127                              & 0.7761                               & 0.7599                               \\ \hline
	\end{tabular}
\end{table}

Podemos observar que en la medida que aumenta el k, los resultados son peores. Esto se explica debido a que estamos permitiendo votar a más cantidad de 'vecinos' que se encuentran más lejos dentro del hiperplano con respecto a la coordenada en la que se evaluó el mail que queremos clasificar utilizando los parámetros dados. Si bien un k muy bajo corre el peligro de que el único criterio de clasificación provenga de un \textit{outlyer}, un k muy alto difumina la idea del método kNN que es, a saber, clasificar nuestro corpus en base a la cercanía respecto al corpus que utilizamos como entrenamiento.



% \subsection{Logistic Regression}



% \subsection{Bagging}
% \subsection{Stacking}

 \section{Reducción de dimensionalidad}

Se probó el uso de PCA como técnica de reducción de dimensionaidad y algunos selectores de features, basados en test estadísticos univariados. Para ambos casos se vió que la eficiencia, en cuanto a accuracy, precision y recall, disminuía sin importar con cuantos features nos quedasemos. Sin embargo creemos que aplicando la reducción de dimensionalidad o el selector de features se disminuye el overfitting por usar features muy correlacionadas. Terminamos por elegir aplicar PCA antes de entrenar los modelos, ya que lo consideramos más robusto que el selector de features.

% \section{Resultados}
% Describir los resultados conseguidos por los distintos modelos y conjuntos de atributos considerados. Preferentemente, resumir los resultados en tablas/figuras. Mencionar los tiempos de ejecución aproximados de cada técnica.


 \section{Discusión}

Los mejores resultados se obtuvieron con los métodos basádos en árboles, y en particular Random Forest, con el cual disminuyen especialmente la cantidad de falsos positivos (mejoran la métrica \textit{precision}), propiedad consideramos que se debe priorizar al construir un clasificador de Spam. Mientras que otros métodos que requieren mayor cómputo, como kNN o SVM, no alcanzaron a tener la efectividad de otros más `sencillos'.

%En principio los mo
%
%
%%https://en.wikipedia.org/wiki/Bayesian_poisoning
%
%%https://www.microsoft.com/en-us/research/publication/why-do-nigerian-scammers-say-they-are-from-nigeria/
%
%Como una primera conclusión de este experimento observamos que los mejores resultados se obtienen con los modelos más 'sencillos', mientras que los modelos que requieren mayor cómputo como kNN o SVM arrojan peores resultados.
%Los métodos basádos en árboles, y en particular Random Forest, además de otorgar los mejores resultados, disminuyen especialmente la cantidad de falsos positivos (mejoran la métrica \textit{precision}), propiedad que nos interesa destacar al armar un clasificador de Spam
%
%La conclusión de esta experiencia, sin embargo, parecería ser que la cantidad de árboles del Random Forest no es un factor determinante a la hora de evaluar su eficiencia.

% Analizar los resultados, buscando responder cuestiones como, por ejemplo: ¿cuáles son los atributos encontrados con mayor poder predictivo?, ¿cuán sensibles fueron los algoritmos a las técnicas de reducción de dimensionalidad consideradas?, ¿resultó clara la elección del algoritmo para la competencia, o hubo que poner en la balanza distintos factores?


\end{document}